{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McLTqonbRMFQ",
    "outputId": "94977240-d3e9-4bc3-d72a-5d51b5420f10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "830cc070819547e2ba36fd7a4d3548ec",
      "cda144bd9ed34f79b5a0a23add718f2f",
      "d8f239b3bd174063a40b8876df12fcb0",
      "d73a9157ba45433abdd41a798e2004df",
      "357495ebdc0b427d93763290f2596cea",
      "15c15b1c627046e68f0928800f1531ce",
      "a5a46e7a6f7e4ba484adb7cfdc9ad932",
      "9fc2d19025fe40fb9ee4e3abc465cd3b",
      "5e719e785eae4c09ab5ff6faed90e5fa",
      "f7900916e9b946ff8cb1ce600155a9d4",
      "bdbc874ef2bf48cf9d95067cc5b11f4b",
      "4b8309dccecd428cb16094a3c3f82b1b",
      "80c6f0a69d1e46dcb7e037319a0b0298",
      "ff23db24ef97440c92353feb516c18f9",
      "b81cd9e880ac41c6b90f70d6a19df80b",
      "aec462c3b01b4f70af2ea4e05983c41e",
      "7f3457632265467d87e6a5ab2586347b",
      "3b795ec854234a37b925695f88479d0f",
      "c2f78c0a8f034a1d8668e1c85364f456",
      "8f6c13acea4445c095b68bfa66d9b1cd",
      "626b6c97cf274008be34d823edec5eee",
      "bf0d16761a5d455994437259155d0c1b",
      "1c4bfb8d53b44cfaa1d5f4408c09dc1e",
      "877663aad12d4788a74d956fbf81d670",
      "c492931567f74f5b9e6713cde9d99bcd",
      "503853e6e5c640aa870eacb8d37cc155",
      "e060e39fb6444854ab7c2737ed25001c",
      "1f8593e225084064ae49881557db05e6",
      "7236567a44674420b410c934d90e3214",
      "b64d390ceec94cae9bc0f38fd49ee9cc",
      "2a746e9592694102afda248b14002eb8",
      "470382e8b27547da8b8f0f3f849101fd",
      "2d276f94c44b4807bcb408ddc6689345",
      "34cdc8e5335349138b5a70ce0e32f9df",
      "c1a87cd1b9cf410dad53309225205a64",
      "1d057590832f4dacbb71e3bcf8fc4dba",
      "48727fd2945f4a1c81ff7e35f73641e4",
      "2c8220cb8d174ca4a7aef90c3675e0d0",
      "38312554d4a843d98d4f275a67e32929",
      "7f58b8160ab04c3785a8933e86fe651e",
      "08bc67d3d4a64bd18c26a93ba65e89f8",
      "25d83a9a4efe43588e93793d8f1bdee3",
      "644b29555ca8423fa26aeb50d13d3d2d",
      "d403dd8536eb4a4e9393049cfe172214",
      "0d45e21d91dd451d8bc274aa3389ee99",
      "95b94bb6093244dfb48dd6f2dc9e215a",
      "6f6576be0a644e4286b559ca8ec5a27a",
      "a15b4c9a8c9146c5a0e0d91330bd85f6",
      "cbfe5a2f49174c7c929b217e830df244",
      "a7ecd6ecf0f9418bab5eab0fc5da9998",
      "f5a1633da9bb4b86a0399a7d5fcf98b0",
      "696fbcf0144847478b042f1a77c5e571",
      "cbad9c451b974210b654a20f70668cac",
      "976239a827554b7e8f36fe90d979a887",
      "edef9a33995d4f2294dd4258e224a100",
      "67ce69b1fb8a4eac9ab9141b526732bf",
      "b17ec17865c2438d8c1f69596ce60e16",
      "278da986b0b74afaa378ba913d4b19bc",
      "ad04f95f7d574f478d89ad1fcfcb00bf",
      "521373e3f29947f1ab863c8f23224c65",
      "526363d8771f4f68be3b624d2284f104",
      "e0dc6fdfe25c4b9ea1a9b074072dc15e",
      "0f973e20b2844aebbde60efcab417c93",
      "229ce815db054ea1a076b8f9db2335fd",
      "8f56352571e841d39e8d98e654293443",
      "6f8c96ecfd534d6cb9a8017604cb3e70",
      "b3baac7aa6894b338eea2dd1535430d8",
      "78a8dace98d7462c819434f9c8bfb90e",
      "1eba096e015f407abcb77910f61d5034",
      "b7b124827a4e4274b5c2b4b73489cff8",
      "04fa0d1d54f6432cb74148da96b9af78",
      "481727272f874ec3b05ee459b809069e",
      "24d11c59ad1345efa27061adfb7e8a09",
      "54d37d2bd7ba4fd8835faeae49d3bba9",
      "b9b06e24580144ea97b67734fb50bbeb",
      "a4e6b32bd2d2487d9a6fed9ea7d3a34c",
      "a9e21678826a43f092e11a0959643bb3",
      "84e21f326ffb4fbfa42a0312c59a4738",
      "a0efa831b2604089b7818e6f204d1b66",
      "db2564d00f53464ab37799f27095b0a8",
      "d12792f794f048fa80001a82ebfffd5c",
      "0caf5e8bb2454ee3a64065255982f228",
      "b1e97ef0aa1149f9848f5f58090521fb",
      "d36374bb031a4022aedb584274555df1",
      "eeb1367d74e744718bc39f726681a54b",
      "e3d2091c4221426e9b2116e490f056e0",
      "366a426582fc426c96ea5448524fcad8",
      "7fa3bbd2971b470aa23aa213fd285f42",
      "7e0503a464a84b9db99595d9ab18826e",
      "8f92b305cd354f08a7a9eda972ef6c71",
      "600318f830e7473d8895079f7a4e3609",
      "6561149fe0294c5dbf0f0bf761bbe53d",
      "83366484d3164580baeb0a63db251055",
      "8ed43648b7fa422a836bcf70defa18e1",
      "9bcfaa3e8cc64290a82887318baebd92",
      "c3fb2fed5ce94635927d8e2b40c747bd",
      "39cb3818003940618d8d6fc5cb6374e4",
      "a1074b1d1f1f4bcfb60b346d07d7f75c",
      "6e1f6816ced340f7ab94c4cfec882d04",
      "e09fa40562524aac800899d27a75afd9",
      "e4b9c10ea7cc4340bfa79b6cdb1f43b3",
      "51d71574707d4329af7e0910ce410d61",
      "dd938d5965c94c9384bbe5b5ce48cc2b",
      "16d479cd8c0d4183964ed13e12a92fba",
      "ac606ebdfa35479f9135849f5b8b5dc6",
      "443ecdd6d67449d4965a0ed05b69debe",
      "8e7aa16e4ecc4364958d2eaa14e3cc25",
      "714d53686fb447ab9ecd82ed2e57dd67",
      "0c1546dc06dc4d848a32fe70be45ad24",
      "bfc4339d9b3d43a38a7c483e36161f46",
      "383e9c40f4354edebeb77d3d77e0fcca",
      "a1812552c25f432f8e31f08732df3a75",
      "e8dd4d92d82b4ad7bc02e325e57b1cd3",
      "ff2f69c42f0d4216b3984596eb51adac",
      "72c50b0f4e684d5f992d01aa9251c355",
      "7f14e6c508044307a9c47018825b8b17",
      "381285fee880474a833b5d3398357eed",
      "1ac74f585abf44d5812cfa64faba02ef",
      "c5d85e8a6b0242f699596b60ad809121",
      "07ce5754c9a84a70b99081a76458b5ae",
      "386f4a9dabf44d2f8a2c2e0fc1b24093",
      "c36213d8e9804b08a098a138075e8289",
      "ca8b1366daf34bff9ba4ba7cb5e79977",
      "e60f438e8ecf43409b7d44101581a10d",
      "850322b3628b465b93cc404fa7fcba74",
      "add9f735e84c4937b4196909878e986e",
      "dae7d1fc891e4ef3b3aea291c8313f1f",
      "655e310da9f744f2a1c85e0bc0f8cb87",
      "f332c99215994f4ab746e0cb3c8667fe",
      "18506637edd44813bcff1d11402973ff",
      "481611aae207493fa03d4c6d322c156b",
      "d790b5960c5140a4a58e5efbfddc6746",
      "2733a28b16f042ff94fab68439e4cc2c",
      "11499eae1d524ecd9b1b1fbd76f0ce1b",
      "cee240ff6cd748fdb9fd7a74079af920",
      "9efe5cd10c7649a497b127e350c63374",
      "e2933ace74d14611aa5ed559dffe2c73",
      "cc45aa17620046a3a1e4ec2aea5cac76",
      "765812ca1bf54a539c474bb4aaab40b4",
      "b4be53b9878f4e87abb255526984b044",
      "39fb96bd1b5d4416afa1bd9c416d115a",
      "6bd0344775f2472b9d67b8f9929c5fcc",
      "2138fc9854654e32a215a0c1c5849b0d",
      "fac9c46dae31455fbc4c711191229702",
      "4ba107913cab4113a064889daac805d5",
      "fd109f97b3af4fd29515b2d81a01da34",
      "1e59bfe92cad465797f13a9bf856b43e",
      "530e4841fff946be87feda81eb4cc6bc",
      "e6e78d0eeb1142ae950dc7cf60e34b0d",
      "9e6e59ea744d49fd913d11737d76649d",
      "804a72206c144d109788abd5151b2929",
      "7194777fedf24c248ceec954446143cf",
      "27815fcc1fad4e74af2394707a3efc96",
      "032a26edd0ac46f4897a479d7505e757",
      "7da41a1c4b544c72b4abad96f15cc3e1",
      "cae440bf75834d1ebf21fe96840da6f4",
      "9362304fdbd7444fa4b007a2bcc3dcff",
      "18fd3e6d3c314722bbb2cf403b7a1b1e",
      "446411a137f94c9192fc97f623300812",
      "29c478cf15cb46c1badae6062b971d83",
      "1a90803621f44dbf95e68200a203a56f",
      "760b59852d6a4c9f81af6e4f3e7421a4",
      "ca3b2528fac443368081dfd1edf1192a",
      "0d6af90d6e484342a4b04d43a6213f9d",
      "303c9b0b89fb44399f13e74aeff1c64e",
      "c42a77b496bc4487bfe74c7cdde66eb4",
      "c86f5e9e84db401b8a68432de343a0fa",
      "fbe6148d2543471a840ee62d6993a4e9",
      "a56bd49c6fc442d6a53b3b35a1763cb2",
      "ac9a0bef54f84f2fa555a1d7b435d05d",
      "8aad38ef8ae14abe85ea0aa86c8f2b07",
      "f8023b37c37c487da067c87a263116ca",
      "e96be66e9a0f4a65b6745b1cabad4290",
      "080bbf849f854341ae7c13950687d573",
      "ba3d31ffa8b04470b95bf48ad5d61b12",
      "941e5dedd6ec423b840eb4dbd4da6d05",
      "a2f4375b1ce54172b4241ae1376d75a9",
      "d658a1dffce04866a9763ae369c02564",
      "241c221546ec4369a634cfd5b00c1729",
      "6d0ad5c6348c4e578bb1054f0e8dda70",
      "85fa34f3660849789d3cd0d9e5daca4d",
      "619fabc93e794927baba0ebcdbedf1a2",
      "ecdbb6c1df654daba83f2b193652e398",
      "863f85bf078d4e289b4182c98e4a2327",
      "0c861233ab944555ba7c05b6455762d7",
      "50fa2d08b74443a6994d3409a04e8a7b",
      "d16c5cdf69a14e73964624da56a0915b",
      "0608dc86f2f34b7fbf0a35ecf2111735",
      "58f42af5ec534b99abbb37a293b409be",
      "9da8d1d6115e4e4299052ae760d5dfa2",
      "e2b47cec41e843cb89718a21dc1c1ddb",
      "860eed106a404bc9b855fee89443f748",
      "73b358b9b4ad4aa1aedaebd10e007907",
      "0f6075488ff64d48a25fea397684fbf4",
      "169b76d3c7ff4429b0fe5de991b40da6",
      "a7f80ea83cd24f669566d3e74870e0f9",
      "a78a756ddb174c2da628fd605d14599c",
      "ddfdcb5e8ba54793a94cd505f21fecbc",
      "9f659f8abe134b37a84238569d5cd4fd",
      "f0cb164c6d5e4691b0971673d726b97e",
      "986826583f444df9aee594c708880508",
      "96dd7fd1e09e43f0bce9ce86233d4314",
      "02a3bb7a859b418ea37566e9fa3fac59",
      "ede6cc344a314f3791f114785f7af0d3",
      "9a1339ce0eeb4d4e8a3a57d9db9a58fe",
      "bd3eb3c5381c41649e75bba7b2323b93",
      "b8fc3d7a6e2a4d8596d98c7d30621a81",
      "6b7ffbedbd9c438c96428c97f97fb5cf",
      "98639f3059e2457eb0081427c2ea4d1f",
      "a3d8713cfe684c8588fd65956a6d61fd",
      "4e51a9dd7d264a8eb731808286951c03",
      "c344a3763d814b4bbcb5f974f3e5ab42",
      "b42a3660107c4e38a206ac1e9cf8cdfe",
      "5a068e8a70a34ac08630b0c1642c1dde",
      "d9c1b3e5b7cb49e4a915b71ec9a6b45c",
      "c6ecea8cf28f4a938597b1934b5bb401",
      "36d5302705714fd59e99f9f520204695",
      "737cd4a3ae8f4f65aa9617c8a4737369",
      "b9c04cee1553414da16915ce447bd767",
      "d87ea7d6c1da4be1b6affa86c8d47539",
      "77c4081b5d9c483892e58ab2cdebc24b",
      "e6768f459f5b414b99734e9021eac853",
      "29097d29e9334e9587317f44cc67cc28",
      "3efd59de05704dc39e8465f4e3f587e8",
      "0de470491669443ca62b4991ad8d74fc",
      "0c8426315fa1454b81fb5f6804431ac7",
      "d60ff8095ce64a96a640fd9fc726117c",
      "6ed4f1013c01466ba1fee4a8ab9d8de9",
      "7926a61e1dc840d39b911f75926adaf9",
      "653298f1dd524351b56ffa5798775c88",
      "f1baea6ed46d404b9b7ab5f78f4fe82c",
      "260d652c18a3488e9f787c19f4d930b8",
      "54a6af23802c4bc6b74c5a2377657cb2",
      "e0f2fe75842a445fbb1c7c958404d7ed",
      "0368fbe698bd4333a967b3580c9a8f43",
      "fdf423849653423896c116d116cdf399",
      "1d65a2005e7c402c867de6c0b1f65386",
      "f94d0e29fa21436ea702a9c1f5f93ddf",
      "ea878fd7aa8c46aba5aeacda0da13d04",
      "f248b58b17334b42add4dbc7f1541cb8",
      "f9909495c8d54ea4bdd1559750d2047c",
      "2f4ec98db39c43f7b73ecf67187c99d4",
      "cff86acc3e1c48eebfa0eb980bf95e28",
      "713b4703fdbc488c8b4e26d56a62d42b",
      "faa3b1b39e3d44f6ab6f2011056f7210",
      "571f503d5f35434fbd616c7ffb717ecc",
      "46ae8bdbf5ed4e1cb7520bd72a94901c",
      "ad18a444ef224fcc86489f93efe508d3",
      "84e705ca0f3c48a69ccbb4bb7982a25b",
      "5e631edcac3c4796838bb0f98f8915e7",
      "9e5ab28aad74442e99c9f613a599cc7a",
      "f88043f184a84a2798b18b2dd2daf047",
      "6bd440943c944d23bab6dcf637c6d9b7",
      "d6a1e502930c4e12ba836ddb2177bcea",
      "4961edb46ce147ad9268b92c8ab35420",
      "8f9f8b292ad849309fb46b9074ff773e",
      "883be7f6b303406991990357c9196e3c",
      "35dee32dfc30454780b47d4f7429584f",
      "6e86f61174ba476285bee62edbc32b31",
      "eab72c1afd6e45058bcb96914eb513b5",
      "6096f701979c4be69e2ddc6d9e47f39f",
      "6eef47f9f8f14f5db23188bd0e5f169b",
      "be6a5b12100f4e0494114ae08dbc7954",
      "731901ac9cd245bb8987edb929366759",
      "1132d0b4ed474d48ae6eb0d9a6670610",
      "a28ba108234c46c692c5abdd7c17ffa0",
      "92e63d266dd9420e8e4c3375a9bfe140",
      "a2b81c7bcbe04e71afdd20b2c3cb43b8",
      "c926d80449d047bcbe59f4e4722d29e1",
      "341175f6fefa4c419ff3b255c2160580",
      "71288b36742348d2b34e986d01bbf931",
      "b6d6b3f10b634c20a192720aa958b108",
      "3935ae5009954e259fbba38cdaf29810",
      "7a1fa2b03b554b1c8450f999128684db",
      "c6225b7a1c904300813b5cabc3d5c05a",
      "443ee3fcee4f4b67a4c165536a771a38",
      "b3f0477a1135465ca9ef18015109b1d0",
      "9c269e93bc1a4a55be1cf8c9b5c1921a",
      "048f0ebcc1a142728eaa40795883bdee",
      "c47535647dfd4aee8211ec8732b299b9",
      "b09248e3963643eeab7ad44bd22acf97",
      "2211c4e6ddf843478a9daef5ac191b37",
      "66efbe60c5094511ad1aa164f5e00840",
      "09d1c8ebcddf4e0db97753792ea1512c",
      "0c32a5cd0cd64ae0b89e5ca6ffe23713",
      "23429b1b93d64fa8970d92cf6c28dbef",
      "aadd3b38fe104b859305df11d9a4963c",
      "ebf8308a417248e0bfcfac3bcb869328",
      "b401263b26a044ac8ef553af604ed197",
      "fa0704e3252c458db8e577e1438a79a5",
      "d4f3adf643fe49988a81fad5aed6b3c0",
      "c7acee7791334b75b882f9ba2709116d",
      "c821085f99e847dd9a0e7145cd052a07",
      "eb06e0b479f5447f9d1b5d651ff50df5",
      "ed2c56b5335a404da7590f921e584817",
      "5f794b4651b047c5ba6ddc5d17d109fa",
      "b733321c63de4b399690b41bfcc66621",
      "55cda0c4fa554ee19f671a6955124cfc",
      "c1cde3071eb84d21a5830dc7cb5ae6ef",
      "7ddf6b6c12784002a8143e75757428a9",
      "eac3392ca02c4404be862351a581b7e1",
      "1966dc44dbd540cd93c3c6356bc15ab2",
      "380e1a9b6faa46afbfe21a73ea69728e",
      "e215ce32b0cd446d9da32cae63e602e8",
      "27bf7502bcfc4cb2a7057163814acdc2",
      "ab3dcc5cef1a49e4ac679217c95ff86b",
      "2f25eab0d3e9428cba53fddc79591608",
      "629c5782b6ac41b8b9a1e2840ff76088",
      "c0f53131dcdf4a568fbff68d86a1db63",
      "92e961eb9d064f1c9a80433b981b74b2",
      "ec51a9458bb24a71b0fb1df97ad5178d",
      "bc5a66f4b89643e3974b906623aee0cf",
      "50bdc9dfced849d784678e8ae7f951b8",
      "19f4a74c96bd4bd6843569260f422b9c",
      "aafde56fd86241b799e4a30f342e626c",
      "fece4c7144bd48ecb41286f18ae5e320",
      "13c0432e8d0c49ae8eda223c05084966",
      "d0cde1d2f93048ed85d4e7efae067341",
      "31e01907368f49fe99cccf43b0d8ae5f",
      "1af3ba2d72e34367b0d15b7f7f409b95",
      "d20d8d5f4f724676bfc1452db8ef3f8e",
      "2bfcd16a97c14c6c80373659cc582186",
      "ebe99c271a094c85b8a442a1a0442308",
      "958ecb300ad7452da923aedc7278cf41",
      "dee9106ffe0c4dffa4385f220413748d",
      "9a764cbae7f943bf90d88eb25b95bc25",
      "0e4ac04f49ff48038f70cecba6207f87",
      "2199799dbe0e415eb78aa340caf642a0",
      "8511055ae51a4ef3b3c471559edddd1e",
      "f3676bfd46154972a14af2f32df8f54f",
      "bb5ac5bcb0c542fea60a962fe7308d39",
      "2f448aace8ad404fa86d17b51857257e",
      "6f160ef6ab4d42f2985d3cdf0bdd959f",
      "14873a41d4394205bd6d0a4fdda1ce5c",
      "6934c8c3086e4a9aa4f26ef3ec383181",
      "76542f4eb3ae4529957757492585b5de",
      "cb8d3bedb4274e44a95e39ae629fc96f",
      "f6c673e13f344133803fce147e8c29f2",
      "2342cdc87aec4985b0d41669aee86cd9",
      "b7ba811c1b6644fcbf5b35f6008eb234",
      "88b820f4d9f9415d8071a287cd2fcf6c",
      "5b543b1f75d44bbeb77f1415d2742cc6",
      "61c2649f27d742adaf51fde04824725c",
      "920d566d6c7c4feabdcf7d5a85c61f54",
      "5446302491e84fba8f2a641ab0c9422a",
      "abbfcb3d872b4e58913354cdb1091d6f",
      "1b172787a76546e78aaa8581e45e1e27",
      "3f95f7c6fb1c4012b63680f9f492578d",
      "eb664314c5044a7caaea22e7013904f7",
      "fb9e07fb8e7840918151f81bb34d892a",
      "f665ec64e5e642e3895219c36b193e35",
      "2ad31f3b8ddf4cdf8da671b9610bf80f",
      "57dd1a9a661b4c2aa4d25b47d284cb5e",
      "b987ba8ba6ac46b08634984a2b9f95e4",
      "ea059a485e9248c0804b960c914d4449",
      "0426c7631d4d452cb9f04fe3c085b939",
      "2ed527c719af4cd793dc538515c76df7",
      "1c827f2040134d2eb15d7a2a16c55f0f",
      "c808c87fa34b4753864f597b9e8ba143",
      "f5da358fc3534633b28de89abd92802f",
      "82674ae1a48f4d54a859e44ac8e1a13c",
      "d6961fb9cbb64d6b8f1d883e0d0610d2",
      "b0ed9eb7d8a447db9552e758b9cc4b66",
      "e64ec05dd0fd4c62913370ef4c0da639",
      "8baff002b7dd4a82bac831782e3399e2",
      "67c2b12588a34198a910e7e86ebcf47c",
      "2f2aba628c3d4380a59207d738e85621",
      "60de7bd5127a46f585abd6fa9500cd94",
      "1eba1c861a54442abc61afbf10270c05",
      "c1bc5025fd5a4a989d2b4affaa61cc12",
      "1319d66c53ac40e4970debcf2605772f",
      "f5b488ca18f44d408064e770dc638c87",
      "66b061ed0f564cf19f82300fc69610cf",
      "c78c20bc6f804a9ab17cc1ee7a827563",
      "8e2b3b011aee466e8443fd9038e4fd1e",
      "79892f25850d4e46a6bb88f7365bbfe5",
      "70635c5648d8482b8175a69f91c5a204",
      "a39c53757690486ab801e7d9925c4d8f",
      "e14a2e0cddda490c96e4a1c837270792",
      "06a2bfa08fb6489ea5abc049946ac4a6",
      "63a9eba8c2fc425d99447e6f30c6e56b",
      "d709b4c0e9394f0cbc0dd5ec955906a9",
      "27bc5acc474d445d8e900cb679942ab9",
      "42739ced4dd943c1be7de27d4454f844",
      "082781ac76a641e7a65a4d7020c9b994",
      "f6297f9e0521463f958fe7700fd755ab",
      "0622eb2ca8cb4202b4e1f82b88761c89",
      "1ae87ce6a7ce47b8851d4bd529ca9e07",
      "d4a25fd2c6844691a1e0860791ff771b",
      "e1ebb1163ba64070bc7cd6aaabae62c9",
      "7b91a968c344493e81d45f5623213d8c",
      "d55b7e90e1eb44c4b3e6a70ed9778206",
      "6b4109093ad2433b8829c102cc305c33",
      "9e6a29c345c2472fb54928e38b3e2808",
      "f5793c158232414a9b00e811eb48edb4",
      "580e82e8f39348b9ac8c2a5c43e46289",
      "d01ee132952b464180eafc1c13f257b9",
      "f44c1f8838254620ae89d751cb94c361",
      "cf473e7bf2604f81aa2988c60baa6767",
      "5d21dcfdb77845b4add0d99a8e1fff1e",
      "ef8cdf27318a42d880e2f130e8295172",
      "6565a38eb878445f8aeab540f7518e10",
      "7b557a4386e94fdba26cee8096b27642",
      "147d134c276347c5bb1566d4f3e846a7",
      "b734eebde9434a1db60e2346b1d8352e",
      "eafe48370d314b6d9acdce34c9767ba9",
      "8ef548ef87964a7aadfe13360e221e1d",
      "c5818e74b0ce47a9b67bf59eee4938cc",
      "2069755240c54a3b86ca2196a5e4c241",
      "6dee29cc98e4487e9c57e2238393ef4a",
      "10db33260b594f70b1b24e3bcdc7f9ff",
      "b2269435284b44b0817985a8ea2659ac",
      "00514976c2204a9b93370c1cb5944cb4",
      "ed5d8d79e3cb46028ee7408c8bcc6845",
      "6566a501119c4fb18803cd96feddef4a",
      "b94eb594ae7c420da9c02459c5ae7a86",
      "d5c5444bed8c48458b35fd5d7542dea9",
      "4a6b2a0c0f364ce388289d80f0c61959",
      "490aa067d61d4f9f9254d0739f5bf9b0",
      "4e3204b9df524005a5034813cb174151",
      "c3eca3cbf0ab47ffad8490b07f7d20d5",
      "bde58dca864547bf9ff794d9be99649a",
      "f8aebaaf8ee8428898c9fd71f4e936d4",
      "5759e1a23b8f4b8799de290af317e058",
      "9f37b6190d054559a3fa12cbcd4b0880",
      "195c8278f530423ab66cdc503acebf03",
      "d3656a4e361e4381bac802b5162c002b",
      "d55fbacec0a643bcaf7a3da75b53bd3a",
      "ba251b6084534a2e85ba47f2f6aad210",
      "4fa78cabf0464430a2188f30279152b2",
      "003f82fdde114a36936bc6e73a0e8ab6",
      "70e8a6aaee3d4ddfb88807490dd7b097",
      "2751090cce494885ba81314a8308f3c7",
      "d06c3e38d1654dafadd9180c10d45f80",
      "f70a09937642498ea4640105bb3c939c",
      "1011b77858524d739bc29f0c1f2044cd",
      "ce41ccae9b264ecab00aaac9951ce806",
      "86a429e27c774c05adcbffdae0fab1de",
      "b7fc3695653c4e6ea79090fabed20164",
      "9c9a471b055f435ca40e5da172e9e9f7",
      "e2e30d2964484e5382edc96c1da0e7ff",
      "b2d48815b4b64421b6b8b9fb8d19f210",
      "2e09895d8d7543b8bf5fc105a0b44bdc",
      "0d0038ecf1534b37a72df25a6a7336dd",
      "7801c974a7944c27bdb81a7d4a5e1330",
      "ff4a962479524b2884321c42c4a52a55",
      "d353651ab8fd480ba6562884460d7792",
      "654ac1d4e48a4801a27f71bc64af3c46",
      "5d9f9d71aefe4bd89807f2a9a33637ea",
      "266bce28721d44358d86021762702363",
      "5d011fa10d894406a01d8097d507acfa"
     ]
    },
    "id": "HalWhmMIchey",
    "outputId": "54a36ddc-a2a8-4d5a-e94f-0f01d55eded2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, models\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "import requests\n",
    "from google.colab import files\n",
    "import time\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load Together API key manually for Colab\n",
    "TOGETHER_API_KEY = \"1fe0076c178dc228a74675178f812ae53c34207ae9a271bb9c370530889cfaed\"\n",
    "\n",
    "# Test questions\n",
    "test_questions = [\n",
    "    \"What medication is recommended for acute bipolar depression?\",\n",
    "    \"What are alternative treatments for a patient who had side effects from quetiapine?\",\n",
    "    \"What is the recommended treatment for mixed episodes in bipolar disorder?\",\n",
    "    \"What is the first-line treatment for Bipolar II disorder acute depression?\",\n",
    "    \"What medication should be avoided in obese patients with bipolar disorder?\",\n",
    "    \"What medication considerations are there for pregnant patients with bipolar disorder?\",\n",
    "    \"What medication should be used cautiously in patients with diabetes?\",\n",
    "    \"What medication considerations are there for patients with hepatic impairment?\",\n",
    "    \"What medication should be used cautiously in patients with cardiovascular disease?\",\n",
    "    \"What medication considerations are there for patients with renal impairment?\",\n",
    "    \"How should rapid cycling bipolar disorder be treated?\",\n",
    "    \"What is the recommended treatment for schizoaffective disorder?\",\n",
    "    \"What is the role of lamotrigine as adjunct therapy?\",\n",
    "    \"When is electroconvulsive therapy recommended?\",\n",
    "    \"What treatments show rapid response within the first week?\",\n",
    "    \"What medications help with comorbid anxiety in bipolar disorder?\",\n",
    "    \"What is recommended for lithium maintenance therapy?\",\n",
    "    \"What is recommended for quetiapine maintenance therapy?\",\n",
    "    \"What is recommended for Bipolar II maintenance therapy?\",\n",
    "    \"What are common gastrointestinal side effects of mood stabilizers?\"\n",
    "]\n",
    "\n",
    "# Enhanced data loading with better structure preservation\n",
    "def load_json_knowledge():\n",
    "    uploaded = files.upload()\n",
    "    if not uploaded:\n",
    "        raise RuntimeError(\"‚ùå No file uploaded.\")\n",
    "    json_filename = next(iter(uploaded))\n",
    "    with open(json_filename, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    entries = []\n",
    "    metadata = []\n",
    "\n",
    "    def extract_content(obj, path=\"\"):\n",
    "        if isinstance(obj, dict):\n",
    "            # Look for text content in various fields\n",
    "            text_fields = ['text', 'content', 'description', 'recommendation', 'guideline']\n",
    "            found_text = None\n",
    "\n",
    "            for field in text_fields:\n",
    "                if field in obj and obj[field]:\n",
    "                    found_text = str(obj[field]).strip()\n",
    "                    break\n",
    "\n",
    "            if found_text:\n",
    "                entries.append(found_text)\n",
    "                metadata.append({\n",
    "                    'path': path,\n",
    "                    'source': obj.get('source', ''),\n",
    "                    'section': obj.get('section', ''),\n",
    "                    'type': obj.get('type', ''),\n",
    "                    'medication': extract_medications(found_text)\n",
    "                })\n",
    "\n",
    "            # Recursively process nested objects\n",
    "            for key, value in obj.items():\n",
    "                if key not in text_fields:\n",
    "                    extract_content(value, f\"{path}.{key}\" if path else key)\n",
    "\n",
    "        elif isinstance(obj, list):\n",
    "            for i, item in enumerate(obj):\n",
    "                extract_content(item, f\"{path}[{i}]\" if path else f\"[{i}]\")\n",
    "        else:\n",
    "            text = str(obj).strip()\n",
    "            if len(text) > 50:  # Only include substantial text\n",
    "                entries.append(text)\n",
    "                metadata.append({\n",
    "                    'path': path,\n",
    "                    'medication': extract_medications(text)\n",
    "                })\n",
    "\n",
    "    extract_content(data)\n",
    "\n",
    "    # Clean entries\n",
    "    cleaned_entries = []\n",
    "    cleaned_metadata = []\n",
    "    for entry, meta in zip(entries, metadata):\n",
    "        cleaned = re.sub(r'\\s+', ' ', entry).strip()\n",
    "        if len(cleaned) > 20:\n",
    "            cleaned_entries.append(cleaned)\n",
    "            cleaned_metadata.append(meta)\n",
    "\n",
    "    print(f\"üìö Loaded {len(cleaned_entries)} knowledge entries with metadata\")\n",
    "    return cleaned_entries, cleaned_metadata\n",
    "\n",
    "def extract_medications(text):\n",
    "    \"\"\"Extract medication names from text\"\"\"\n",
    "    medications = set()\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Common bipolar medications to look for\n",
    "    bipolar_meds = [\n",
    "        'quetiapine', 'seroquel', 'lithium', 'lamotrigine', 'lamictal',\n",
    "        'divalproex', 'depakote', 'valproate', 'carbamazepine', 'tegretol',\n",
    "        'lurasidone', 'latuda', 'aripiprazole', 'abilify', 'olanzapine',\n",
    "        'zyprexa', 'risperidone', 'risperdal', 'cariprazine', 'vraylar',\n",
    "        'ziprasidone', 'geodon', 'haloperidol', 'haldol', 'fluoxetine',\n",
    "        'prozac', 'sertraline', 'zoloft', 'paroxetine', 'paxil'\n",
    "    ]\n",
    "\n",
    "    for med in bipolar_meds:\n",
    "        if med in text_lower:\n",
    "            medications.add(med)\n",
    "\n",
    "    return list(medications)\n",
    "\n",
    "# Enhanced embedder with medical focus\n",
    "class MedicalEmbedder:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            # Try medical-specific models in order of preference\n",
    "            models_to_try = [\n",
    "                'emilyalsentzer/Bio_ClinicalBERT',\n",
    "                'pritamdeka/S-PubMedBert-MS-MARCO',\n",
    "                'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext',\n",
    "                'all-MiniLM-L6-v2'\n",
    "            ]\n",
    "\n",
    "            for model_name in models_to_try:\n",
    "                try:\n",
    "                    if 'Bio_ClinicalBERT' in model_name:\n",
    "                        word_embedding_model = models.Transformer(model_name)\n",
    "                        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "                        self.model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "                    else:\n",
    "                        self.model = SentenceTransformer(model_name)\n",
    "                    print(f\"‚úÖ Using {model_name}\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to load {model_name}: {e}\")\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error initializing embedder: {e}\")\n",
    "            raise\n",
    "\n",
    "    def encode(self, texts, show_progress_bar=True):\n",
    "        return self.model.encode(texts, show_progress_bar=show_progress_bar, batch_size=16)\n",
    "\n",
    "# Enhanced search with multiple strategies\n",
    "class EnhancedSearch:\n",
    "    def __init__(self, passages, metadata, embedder):\n",
    "        self.passages = passages\n",
    "        self.metadata = metadata\n",
    "        self.embedder = embedder\n",
    "        self.build_indices()\n",
    "\n",
    "    def build_indices(self):\n",
    "        print(\"üîó Building search indices...\")\n",
    "\n",
    "        # Main semantic index\n",
    "        embeddings = self.embedder.encode(self.passages)\n",
    "        self.semantic_index = faiss.IndexHNSWFlat(embeddings.shape[1], 32)\n",
    "        self.semantic_index.hnsw.efConstruction = 40\n",
    "        self.semantic_index.add(embeddings.astype('float32'))\n",
    "\n",
    "        # Medication-specific index\n",
    "        self.med_passages = []\n",
    "        self.med_indices = []\n",
    "        for i, (passage, meta) in enumerate(zip(self.passages, self.metadata)):\n",
    "            if meta.get('medication') or self.contains_medication_terms(passage):\n",
    "                self.med_passages.append(passage)\n",
    "                self.med_indices.append(i)\n",
    "\n",
    "        if self.med_passages:\n",
    "            med_embeddings = self.embedder.encode(self.med_passages)\n",
    "            self.med_index = faiss.IndexHNSWFlat(med_embeddings.shape[1], 32)\n",
    "            self.med_index.add(med_embeddings.astype('float32'))\n",
    "        else:\n",
    "            self.med_index = None\n",
    "\n",
    "        print(f\"üìä Built semantic index: {len(self.passages)} passages\")\n",
    "        print(f\"üíä Built medication index: {len(self.med_passages)} passages\")\n",
    "\n",
    "    def contains_medication_terms(self, text):\n",
    "        \"\"\"Check if text contains medication-related terms\"\"\"\n",
    "        med_keywords = [\n",
    "            'medication', 'drug', 'treatment', 'therapy', 'prescription',\n",
    "            'dose', 'dosing', 'mg', 'side effect', 'adverse', 'contraindic',\n",
    "            'first-line', 'second-line', 'maintenance', 'acute', 'recommended'\n",
    "        ]\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword in text_lower for keyword in med_keywords)\n",
    "\n",
    "    def search(self, query, top_k=10):\n",
    "        results = []\n",
    "\n",
    "        # Strategy 1: Semantic search on all passages\n",
    "        semantic_results = self._semantic_search(query, top_k)\n",
    "        results.extend(semantic_results)\n",
    "\n",
    "        # Strategy 2: Medication-focused search if query is about medications\n",
    "        if self._is_medication_query(query) and self.med_index is not None:\n",
    "            med_results = self._medication_search(query, top_k//2)\n",
    "            results.extend(med_results)\n",
    "\n",
    "        # Strategy 3: Keyword-based search for specific terms\n",
    "        keyword_results = self._keyword_search(query, top_k//2)\n",
    "        results.extend(keyword_results)\n",
    "\n",
    "        # Deduplicate and rank by relevance\n",
    "        seen_indices = set()\n",
    "        unique_results = []\n",
    "        for result in results:\n",
    "            if result['index'] not in seen_indices:\n",
    "                unique_results.append(result)\n",
    "                seen_indices.add(result['index'])\n",
    "\n",
    "        # Sort by score and return top results\n",
    "        unique_results.sort(key=lambda x: x['score'])\n",
    "        return unique_results[:top_k]\n",
    "\n",
    "    def _semantic_search(self, query, top_k):\n",
    "        query_embedding = self.embedder.encode([query])\n",
    "        self.semantic_index.hnsw.efSearch = 64\n",
    "        D, I = self.semantic_index.search(query_embedding.astype('float32'), top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(D[0], I[0]):\n",
    "            if idx < len(self.passages):\n",
    "                results.append({\n",
    "                    'text': self.passages[idx],\n",
    "                    'score': float(score),\n",
    "                    'index': int(idx),\n",
    "                    'method': 'semantic'\n",
    "                })\n",
    "        return results\n",
    "\n",
    "    def _medication_search(self, query, top_k):\n",
    "        if not self.med_index:\n",
    "            return []\n",
    "\n",
    "        query_embedding = self.embedder.encode([query])\n",
    "        D, I = self.med_index.search(query_embedding.astype('float32'), top_k)\n",
    "\n",
    "        results = []\n",
    "        for score, idx in zip(D[0], I[0]):\n",
    "            if idx < len(self.med_passages):\n",
    "                original_idx = self.med_indices[idx]\n",
    "                results.append({\n",
    "                    'text': self.med_passages[idx],\n",
    "                    'score': float(score) * 0.9,  # Slight boost for medication-specific results\n",
    "                    'index': original_idx,\n",
    "                    'method': 'medication'\n",
    "                })\n",
    "        return results\n",
    "\n",
    "    def _keyword_search(self, query, top_k):\n",
    "        \"\"\"Simple keyword-based search for backup\"\"\"\n",
    "        query_terms = query.lower().split()\n",
    "        results = []\n",
    "\n",
    "        for i, passage in enumerate(self.passages):\n",
    "            passage_lower = passage.lower()\n",
    "            matches = sum(1 for term in query_terms if term in passage_lower)\n",
    "            if matches > 0:\n",
    "                # Simple scoring based on term frequency\n",
    "                score = -matches / len(query_terms)  # Negative because lower is better in our scoring\n",
    "                results.append({\n",
    "                    'text': passage,\n",
    "                    'score': score,\n",
    "                    'index': i,\n",
    "                    'method': 'keyword'\n",
    "                })\n",
    "\n",
    "        results.sort(key=lambda x: x['score'])\n",
    "        return results[:top_k]\n",
    "\n",
    "    def _is_medication_query(self, query):\n",
    "        med_indicators = [\n",
    "            'medication', 'drug', 'treatment', 'therapy', 'prescription',\n",
    "            'recommended', 'first-line', 'alternative', 'side effect',\n",
    "            'quetiapine', 'lithium', 'lamotrigine', 'lurasidone', 'divalproex'\n",
    "        ]\n",
    "        query_lower = query.lower()\n",
    "        return any(indicator in query_lower for indicator in med_indicators)\n",
    "\n",
    "# Improved answer generation with context analysis\n",
    "def generate_answer_with_analysis(query, search_results, max_context_length=3000):\n",
    "    \"\"\"Generate answer with better context selection and analysis\"\"\"\n",
    "\n",
    "    # Analyze context to prioritize relevant chunks\n",
    "    analyzed_chunks = []\n",
    "    for result in search_results[:8]:  # Analyze top 8 results\n",
    "        chunk = result['text']\n",
    "        relevance_score = calculate_relevance(query, chunk)\n",
    "        analyzed_chunks.append({\n",
    "            'text': chunk,\n",
    "            'relevance': relevance_score,\n",
    "            'method': result.get('method', 'unknown')\n",
    "        })\n",
    "\n",
    "    # Sort by relevance and select best chunks within token limit\n",
    "    analyzed_chunks.sort(key=lambda x: x['relevance'], reverse=True)\n",
    "\n",
    "    selected_chunks = []\n",
    "    current_length = 0\n",
    "    for chunk_info in analyzed_chunks:\n",
    "        chunk_text = chunk_info['text']\n",
    "        if current_length + len(chunk_text) <= max_context_length:\n",
    "            selected_chunks.append(chunk_text)\n",
    "            current_length += len(chunk_text)\n",
    "        else:\n",
    "            # Try to fit a truncated version\n",
    "            remaining_space = max_context_length - current_length\n",
    "            if remaining_space > 200:  # Only if we have meaningful space left\n",
    "                selected_chunks.append(chunk_text[:remaining_space-3] + \"...\")\n",
    "            break\n",
    "\n",
    "    context = \"\\n\\n\".join(selected_chunks)\n",
    "\n",
    "    # Create more targeted prompt based on query type\n",
    "    query_type = classify_query_type(query)\n",
    "    prompt = create_targeted_prompt(query, context, query_type)\n",
    "\n",
    "    return call_api_with_fallback(prompt)\n",
    "\n",
    "def calculate_relevance(query, chunk):\n",
    "    \"\"\"Calculate relevance score between query and chunk\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    chunk_lower = chunk.lower()\n",
    "\n",
    "    score = 0\n",
    "\n",
    "    # Exact keyword matches\n",
    "    query_words = set(query_lower.split())\n",
    "    chunk_words = set(chunk_lower.split())\n",
    "    common_words = query_words & chunk_words\n",
    "    score += len(common_words) * 2\n",
    "\n",
    "    # Medication name matches (higher weight)\n",
    "    bipolar_meds = [\n",
    "        'quetiapine', 'lithium', 'lamotrigine', 'divalproex', 'lurasidone',\n",
    "        'aripiprazole', 'olanzapine', 'cariprazine', 'carbamazepine'\n",
    "    ]\n",
    "    for med in bipolar_meds:\n",
    "        if med in query_lower and med in chunk_lower:\n",
    "            score += 10\n",
    "\n",
    "    # Clinical terms\n",
    "    clinical_terms = [\n",
    "        'bipolar', 'depression', 'mania', 'maintenance', 'acute',\n",
    "        'first-line', 'second-line', 'recommended', 'contraindic'\n",
    "    ]\n",
    "    for term in clinical_terms:\n",
    "        if term in query_lower and term in chunk_lower:\n",
    "            score += 3\n",
    "\n",
    "    # Length bonus for substantial content\n",
    "    if len(chunk) > 500:\n",
    "        score += 1\n",
    "\n",
    "    return score\n",
    "\n",
    "def classify_query_type(query):\n",
    "    \"\"\"Classify the type of clinical query\"\"\"\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    if any(term in query_lower for term in ['acute', 'depression', 'depressive']):\n",
    "        return 'acute_treatment'\n",
    "    elif any(term in query_lower for term in ['maintenance', 'long-term', 'prophylaxis']):\n",
    "        return 'maintenance'\n",
    "    elif any(term in query_lower for term in ['side effect', 'adverse', 'contraindic']):\n",
    "        return 'safety'\n",
    "    elif any(term in query_lower for term in ['alternative', 'different', 'switch']):\n",
    "        return 'alternative'\n",
    "    elif any(term in query_lower for term in ['first-line', 'recommended', 'treatment']):\n",
    "        return 'recommendation'\n",
    "    else:\n",
    "        return 'general'\n",
    "\n",
    "def create_targeted_prompt(query, context, query_type):\n",
    "    \"\"\"Create a targeted prompt based on query type\"\"\"\n",
    "\n",
    "    base_instruction = \"\"\"You are a clinical decision support system for bipolar disorder treatment. Provide specific, evidence-based recommendations using ONLY the clinical guidelines provided.\"\"\"\n",
    "\n",
    "    type_specific_instructions = {\n",
    "        'acute_treatment': \"Focus on first-line and second-line acute treatment options. Prioritize medications specifically mentioned for acute episodes.\",\n",
    "        'maintenance': \"Focus on maintenance therapy recommendations and long-term treatment strategies.\",\n",
    "        'safety': \"Focus on contraindications, side effects, and safety considerations for specific populations.\",\n",
    "        'alternative': \"Focus on alternative treatment options when first-line treatments fail or cause side effects.\",\n",
    "        'recommendation': \"Focus on evidence-based treatment recommendations and clinical guidelines.\",\n",
    "        'general': \"Provide comprehensive treatment recommendations based on the available evidence.\"\n",
    "    }\n",
    "\n",
    "    specific_instruction = type_specific_instructions.get(query_type, type_specific_instructions['general'])\n",
    "\n",
    "    prompt = f\"\"\"{base_instruction}\n",
    "\n",
    "{specific_instruction}\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "- Use EXACT medication names from the context\n",
    "- Specify treatment line (first-line, second-line, etc.) when mentioned\n",
    "- Include relevant clinical details (dosing, monitoring, contraindications)\n",
    "- If multiple options exist, list them clearly\n",
    "- Base recommendations STRICTLY on the provided context\n",
    "- Do not recommend lamotrigine unless it's specifically indicated in the context for this exact clinical scenario\n",
    "\n",
    "CLINICAL CONTEXT:\n",
    "{context}\n",
    "\n",
    "CLINICAL QUESTION: {query}\n",
    "\n",
    "EVIDENCE-BASED RECOMMENDATION:\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def call_api_with_fallback(prompt):\n",
    "    \"\"\"Call API with multiple model fallbacks\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    models = [\n",
    "        \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "        \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    ]\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": model,\n",
    "                \"prompt\": prompt,\n",
    "                \"max_tokens\": 400,\n",
    "                \"temperature\": 0.05,  # Very low temperature for consistency\n",
    "                \"top_p\": 0.85,\n",
    "                \"stop\": [\"CLINICAL QUESTION:\", \"CLINICAL CONTEXT:\"]\n",
    "            }\n",
    "\n",
    "            response = requests.post(\"https://api.together.xyz/v1/completions\", json=payload, headers=headers)\n",
    "            result = response.json()\n",
    "\n",
    "            if \"choices\" in result and result[\"choices\"]:\n",
    "                answer = result[\"choices\"][0][\"text\"].strip()\n",
    "                # Clean up response\n",
    "                answer = re.sub(r'^(Based on.*?:)', '', answer).strip()\n",
    "                answer = re.sub(r'^(EVIDENCE-BASED RECOMMENDATION:)', '', answer).strip()\n",
    "                return answer\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with {model}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return \"Unable to generate recommendation due to API issues.\"\n",
    "\n",
    "# Golden answers (keeping original structure)\n",
    "question_keywords = [\n",
    "    [\"quetiapine\"],\n",
    "    [\"lurasidone\", \"lithium\", \"divalproex\"],\n",
    "    [\"divalproex\", \"atypical antipsychotic\"],\n",
    "    [\"quetiapine\"],\n",
    "    [\"lithium\"],\n",
    "    [\"lithium\", \"pregnant\"],\n",
    "    [\"lithium\", \"diabetes\"],\n",
    "    [\"lithium\", \"hepatic\"],\n",
    "    [\"quetiapine\", \"cardiovascular\"],\n",
    "    [\"quetiapine\", \"renal\"],\n",
    "    [\"mania\", \"rapid cycling\"],\n",
    "    [\"schizoaffective\", \"antipsychotic\", \"mood stabilizer\"],\n",
    "    [\"lamotrigine\", \"adjunct\"],\n",
    "    [\"electroconvulsive\"],\n",
    "    [\"electroconvulsive\", \"cariprazine\", \"olanzapine-fluoxetine\"],\n",
    "    [\"quetiapine\", \"lurasidone\", \"anxiety\"],\n",
    "    [\"lithium\", \"maintenance\"],\n",
    "    [\"quetiapine\", \"maintenance\"],\n",
    "    [\"quetiapine\", \"bdii\", \"maintenance\"],\n",
    "    [\"nausea\", \"vomiting\", \"diarrhea\"]\n",
    "]\n",
    "\n",
    "question_incorrect_keywords = [\n",
    "    [\"lamotrigine\"],\n",
    "    [\"aripiprazole\", \"lamotrigine\"],\n",
    "    [],\n",
    "    [\"lamotrigine\"],\n",
    "    [\"lamotrigine\"],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [\"lithium\"],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    []\n",
    "]\n",
    "\n",
    "question_comments = [\n",
    "    \"\",\n",
    "    \"Vivomap doesn't specify the combo; lists meds only\",\n",
    "    \"CANMAT recommends divalproex and atypical antipsychotics\",\n",
    "    \"\",\n",
    "    \"Vivomap flags obesity but not weight gain\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"Use quetiapine but caution in renal disease\",\n",
    "    \"Address rapid cycling risk factors\",\n",
    "    \"Use atypical antipsychotic or combo with mood stabilizer\",\n",
    "    \"Adjunct lamotrigine is first-line\",\n",
    "    \"ECT is first-line for rapid response\",\n",
    "    \"ECT and cariprazine/olanzapine-fluoxetine show week-1 effects\",\n",
    "    \"Quetiapine and lurasidone help with anxiety\",\n",
    "    \"Continue lithium for maintenance\",\n",
    "    \"Continue quetiapine for maintenance\",\n",
    "    \"Continue quetiapine for BDII maintenance\",\n",
    "    \"Common: nausea, vomiting, diarrhea\"\n",
    "]\n",
    "\n",
    "# Main evaluation function\n",
    "def run_evaluation(passages, metadata, search_engine):\n",
    "    print(\"\\nüìä ENHANCED EVALUATION SYSTEM\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    correct_count = 0\n",
    "    total_questions = min(len(test_questions), len(question_keywords))\n",
    "\n",
    "    for i in range(total_questions):\n",
    "        query = test_questions[i]\n",
    "        print(f\"\\nüîç Q{i+1}: {query}\")\n",
    "\n",
    "        try:\n",
    "            # Enhanced search\n",
    "            search_results = search_engine.search(query, top_k=10)\n",
    "\n",
    "            # Generate answer with analysis\n",
    "            answer = generate_answer_with_analysis(query, search_results)\n",
    "\n",
    "            # Evaluation\n",
    "            prediction = answer.lower()\n",
    "            gold_keywords = [kw.lower() for kw in question_keywords[i]]\n",
    "            incorrect_keywords = [kw.lower() for kw in question_incorrect_keywords[i]]\n",
    "\n",
    "            has_correct = any(kw in prediction for kw in gold_keywords) if gold_keywords else True\n",
    "            has_incorrect = any(kw in prediction for kw in incorrect_keywords) if incorrect_keywords else False\n",
    "\n",
    "            correct = has_correct and not has_incorrect\n",
    "\n",
    "            if correct:\n",
    "                correct_count += 1\n",
    "\n",
    "            symbol = \"‚úÖ\" if correct else \"‚ùå\"\n",
    "\n",
    "            print(f\"{symbol} Q{i+1}:\")\n",
    "            print(f\"    üîπGenerated: {answer[:150]}{'...' if len(answer) > 150 else ''}\")\n",
    "            print(f\"    üéØExpected: {', '.join(question_keywords[i])}\")\n",
    "            if question_incorrect_keywords[i]:\n",
    "                print(f\"    üö´Avoid: {', '.join(question_incorrect_keywords[i])}\")\n",
    "            if question_comments[i]:\n",
    "                print(f\"    üí¨Note: {question_comments[i]}\")\n",
    "            print(f\"    ‚úÖ Result: {'CORRECT' if correct else 'INCORRECT'}\")\n",
    "\n",
    "            # Show search method breakdown\n",
    "            methods = [r.get('method', 'unknown') for r in search_results[:3]]\n",
    "            print(f\"    üîç Search methods: {', '.join(methods)}\")\n",
    "\n",
    "            time.sleep(1.1)  # Rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in Q{i+1}: {e}\")\n",
    "\n",
    "    accuracy = (correct_count / total_questions) * 100\n",
    "    print(f\"\\nüéØ FINAL RESULTS:\")\n",
    "    print(f\"‚úÖ Correct: {correct_count}/{total_questions}\")\n",
    "    print(f\"üìä Accuracy: {accuracy:.1f}%\")\n",
    "\n",
    "    # Interactive mode\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ü©∫ Interactive Clinical Q&A\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nüí¨ Enter clinical question (or 'exit'): \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            search_results = search_engine.search(user_query, top_k=8)\n",
    "            answer = generate_answer_with_analysis(user_query, search_results)\n",
    "            print(f\"\\nü©∫ Clinical Recommendation:\\n{answer}\")\n",
    "\n",
    "            # Show evidence sources\n",
    "            print(f\"\\nüìö Based on {len(search_results)} evidence sources:\")\n",
    "            for i, result in enumerate(search_results[:3]):\n",
    "                print(f\"  {i+1}. {result['method']} search (score: {result['score']:.3f})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üè• ENHANCED BIPOLAR DISORDER CLINICAL DECISION SUPPORT\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    print(\"\\nüìÅ Upload your clinical guidelines JSON file...\")\n",
    "    passages, metadata = load_json_knowledge()\n",
    "\n",
    "    print(\"\\nüî¨ Initializing medical embedder...\")\n",
    "    embedder = MedicalEmbedder()\n",
    "\n",
    "    print(\"\\nüîç Building enhanced search system...\")\n",
    "    search_engine = EnhancedSearch(passages, metadata, embedder)\n",
    "\n",
    "    print(\"\\nüß™ Running enhanced evaluation...\")\n",
    "    run_evaluation(passages, metadata, search_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:ipykernel_py3]",
   "language": "python",
   "name": "conda-env-ipykernel_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
