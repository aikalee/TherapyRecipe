{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c317040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the following command in terminal to login\n",
    "# huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b836fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file\n",
    "with open(\"../data/raw/queries.txt\", \"r\") as file:\n",
    "    queries = file.readlines()\n",
    "\n",
    "with open(\"../data/raw/answers.txt\", \"r\") as file:\n",
    "    answers = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dce16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f74d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedder = SentenceTransformer(\"abhinand/MedEmbed-large-v0.1\")\n",
    "\n",
    "# similarities = embedder.similarity(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15293c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/guideline_db_with_img.json\") as f:\n",
    "    db = json.load(f)\n",
    "    \n",
    "with open('../data//processed/Exp2_MedEmb_with_img_table.emb', mode='rb') as f: #replace with your file\n",
    "    vector_store = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70d56037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '[Table: Table C. List of Abbreviations.]\\nCaption: List of Abbreviations.\\nRow 0 — Abbreviation: ACT, Definition: Acceptance and commitment therapy\\nRow 1 — Abbreviation: ADHD, Definition: Attention-deficit hyperactivity disorder\\nRow 2 — Abbreviation: AI, Definition: Artificial intelligence\\nRow 3 — Abbreviation: BA, Definition: Behavioural activation\\nRow 4 — Abbreviation: CAM, Definition: Complementary and alternative medicine\\nRow 5 — Abbreviation: CANMAT, Definition: Canadian Network for Mood and Anxiety Treatments\\nRow 6 — Abbreviation: CBASP, Definition: Cognitive behavioural analysis system of psychotherapy\\nRow 7 — Abbreviation: CBT, Definition: Cognitive-behavioural therapy\\nRow 8 — Abbreviation: CPD, Definition: Continuing professional development\\nRow 9 — Abbreviation: CYP, Definition: Cytochrome P450\\nRow 10 — Abbreviation: DBS, Definition: Deep brain stimulation\\nRow 11 — Abbreviation: DHI, Definition: Digital health intervention\\nRow 12 — Abbreviation: DLPFC, Definition: Dorsolateral prefrontal cortex\\nRow 13 — Abbreviation: DSM-5-TR, Definition: Diagnostic and Statistical Manual, 5th edition, Text Revision\\nRow 14 — Abbreviation: DSM-IV-TR, Definition: Diagnostic and Statistical Manual, 4th edition, Text Revision\\nRow 15 — Abbreviation: DTD, Definition: Difficult-to-treat depression\\nRow 16 — Abbreviation: ECG, Definition: Electrocardiography\\nRow 17 — Abbreviation: ECT, Definition: Electroconvulsive therapy\\nRow 18 — Abbreviation: EEG, Definition: Electroencephalography\\nRow 19 — Abbreviation: GRADE, Definition: Grading of Recommendations Assessment, Development, and Evaluation\\nRow 20 — Abbreviation: ICD, Definition: International Classification of Diseases\\nRow 21 — Abbreviation: IPT, Definition: Interpersonal therapy\\nRow 22 — Abbreviation: MAOI, Definition: Monoamine oxidase inhibitor\\nRow 23 — Abbreviation: MBC, Definition: Measurement-based care\\nRow 24 — Abbreviation: MBCT, Definition: Mindfulness-based cognitive therapy\\nRow 25 — Abbreviation: MCT, Definition: Metacognitive therapy\\nRow 26 — Abbreviation: MDD, Definition: Major depressive disorder\\nRow 27 — Abbreviation: MDE, Definition: Major depressive episode\\nRow 28 — Abbreviation: MI, Definition: Motivational interviewing\\nRow 29 — Abbreviation: MST, Definition: Magnetic seizure therapy\\nRow 30 — Abbreviation: NbN, Definition: Neuroscience-based nomenclature\\nRow 31 — Abbreviation: NDRI, Definition: Norepinephrine-dopamine reuptake inhibitor\\nRow 32 — Abbreviation: NMDA, Definition: N-methyl-D-aspartate\\nRow 33 — Abbreviation: NSAID, Definition: Nonsteroidal anti-inflammatory drug\\nRow 34 — Abbreviation: PDD, Definition: Persistent depressive disorder\\nRow 35 — Abbreviation: PDT, Definition: Psychodynamic psychotherapy\\nRow 36 — Abbreviation: PHQ, Definition: Patient health questionnaire\\nRow 37 — Abbreviation: PST, Definition: Problem-solving therapy\\nRow 38 — Abbreviation: RCT, Definition: Randomized controlled trial\\nRow 39 — Abbreviation: rTMS, Definition: Repetitive transcranial magnetic stimulation\\nRow 40 — Abbreviation: SDM, Definition: Shared decision-making\\nRow 41 — Abbreviation: SNRI, Definition: Serotonin-norepinephrine reuptake inhibitor\\nRow 42 — Abbreviation: SSRI, Definition: Selective serotonin reuptake inhibitor\\nRow 43 — Abbreviation: STPP, Definition: Short-term psychodynamic psychotherapy\\nRow 44 — Abbreviation: TBS, Definition: Theta burst stimulation\\nRow 45 — Abbreviation: TCA, Definition: Tricyclic antidepressants\\nRow 46 — Abbreviation: tDCS, Definition: Transcranial direct current stimulation\\nRow 47 — Abbreviation: TMS, Definition: Transcranial magnetic stimulation\\nRow 48 — Abbreviation: TRD, Definition: Treatment-resistant depression\\nRow 49 — Abbreviation: USA, Definition: United States of America\\nRow 50 — Abbreviation: VNS, Definition: Vagus nerve stimulation\\nRow 51 — Abbreviation: WHO, Definition: World Health Organization',\n",
       " 'embedding': array([ 0.00180082, -0.03266334,  0.01039647, ...,  0.03144711,\n",
       "        -0.01324609, -0.02038074], dtype=float32),\n",
       " 'metadata': {'section': 'https://pmc.ncbi.nlm.nih.gov/articles/PMC11351064/#section2-07067437241245384',\n",
       "  'type': 'figure table',\n",
       "  'referee_id': 'table_c',\n",
       "  'headings': 'Methods > Conventions Used in This Document'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store[249]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vector_store = (\n",
    "#     list()\n",
    "# )\n",
    "\n",
    "# # Step 1 - build vector store\n",
    "# for chunk in db:\n",
    "#     text = chunk[\"text\"]\n",
    "#     embedding = embedder.encode(text)\n",
    "#     vector_store.append({\"text\": text, \"embedding\": embedding, \"metadata\": chunk[\"metadata\"]})\n",
    "\n",
    "# with open('../data/processed/Exp2_NeuML_with_img_table.emb', 'wb') as f:\n",
    "#     pickle.dump(vector_store, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e576fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import difflib\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from together import Together\n",
    "llm_client = Together(api_key='4f6e44b7689d6592b2b5b57ad3940ac9f488d14c22802e8bcdf641b06e98cbbe')\n",
    "#4f6e44b7689d6592b2b5b57ad3940ac9f488d14c22802e8bcdf641b06e98cbbe\n",
    "\n",
    "with open(\"../data/processed/guideline_db.json\") as f:\n",
    "    db = json.load(f)\n",
    "    \n",
    "with open('../data/processed/Exp2_MedEmb.emb', mode='rb') as f: #replace with your file\n",
    "  vector_store = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "def depression_assistant(query):\n",
    "    embedder = SentenceTransformer('abhinand/MedEmbed-large-v0.1')\n",
    "    print(\"--------- We're using the MedEmbed-large-v0.1 model for embeddings.---------\")\n",
    "    \n",
    "    # original_query_results = search(embedder, query, vector_store, k=4, min_similarity=0.3)\n",
    "    original_query_results = faiss_search(embedder, query, vector_store, loaded_index, k=4, min_similarity=0.3)\n",
    "    print(f\"Original query: {query}\")\n",
    "    \n",
    "    new_queries = rewrite_query(query)\n",
    "    new_queries_results = []\n",
    "    \n",
    "    for new_query in new_queries:\n",
    "        if new_query.lower().endswith(\"none**.\") or new_query.lower().endswith(\"none**\"):\n",
    "            print(f\"------- :Rewritten query: {new_query}\")\n",
    "            print(\"------- :No relevant information found in the query, skipping search.\")\n",
    "            new_queries_results.append([None])\n",
    "            continue\n",
    "        print(f\"------- :Rewritten query: {new_query}\")\n",
    "        # results = search(embedder, new_query, vector_store, k=4, min_similarity=0.3)\n",
    "        results = faiss_search(embedder, new_query, vector_store, loaded_index, k=4, min_similarity=0.3)\n",
    "        print(f\"------- :Results number: {len(results)}\")\n",
    "        # print(f\"------- :Results: {results}\")\n",
    "        print()\n",
    "        new_queries_results.append(results)\n",
    "        \n",
    "    prompt = construct_prompt(query, original_query_results, new_queries, new_queries_results)\n",
    "    response = call_llm(prompt)\n",
    "    return response\n",
    "\n",
    "def search(embedder, query, vector_store, k, min_similarity):\n",
    "    query_embedding = embedder.encode(query.lower())\n",
    "\n",
    "    similarities = []\n",
    "    results = []\n",
    "    \n",
    "    referenced_tables = list()\n",
    "    # calculate cosine similarity between each text and the query\n",
    "    for i, chunk in enumerate(vector_store):\n",
    "        similarity = cosine_similarity([query_embedding], [chunk[\"embedding\"]])\n",
    "        if similarity[0][0] >= min_similarity:\n",
    "            similarities.append((i, similarity[0][0]))\n",
    "\n",
    "    # sort the similarities based on similarity and select the top k\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i, similarity in similarities[:k]:\n",
    "            results.append({'text':db[i]['text'], 'section': db[i]['metadata']['section'], 'type': db[i]['metadata'].get('referee_id', 'paragraph')})\n",
    "            try:\n",
    "                for table in db[i][\"metadata\"][\"referenced_tables\"]:\n",
    "                    # check if the table is already in the set\n",
    "                    table = table.lower().replace(\" \", \"_\").replace(\".\", \"_\")\n",
    "                    referenced_tables.append(table)\n",
    "            except KeyError:\n",
    "                # if there is no referenced tables, Means this is a table, skip\n",
    "                pass\n",
    "            \n",
    "    referenced_tables = set(referenced_tables)  # remove duplicates\n",
    "    print(referenced_tables)\n",
    "    \n",
    "    \n",
    "    for chunk in results:\n",
    "        #if table is already in the results, skip\n",
    "        try:\n",
    "            if chunk[\"type\"] in referenced_tables:\n",
    "                referenced_tables.remove(chunk[\"type\"])\n",
    "                print(f\"Removed table: {chunk[\"type\"]}\")\n",
    "                print(referenced_tables)\n",
    "        except KeyError:\n",
    "            # if there is no referee_id, skip\n",
    "            pass\n",
    "        \n",
    "\n",
    "    for chunk in db:\n",
    "        try:\n",
    "            if chunk[\"metadata\"][\"referee_id\"] in referenced_tables:\n",
    "                results.append({'text': chunk['text'],'section': chunk['metadata']['section'], 'type': chunk['metadata']['referee_id']})\n",
    "                print(f\"Added table: {chunk['metadata']['referee_id']}\")\n",
    "        except KeyError:\n",
    "            # if there is no referee_id, skip\n",
    "            pass\n",
    "    \n",
    "    if not results or not results[0]:\n",
    "        return [\"No matching documents!\"]\n",
    "    return results\n",
    "\n",
    "\n",
    "def construct_prompt(query, original_query_results, new_queries, new_queries_results):\n",
    "    system_prompt = (\n",
    "        \"Your name is Depression Assistant, a helpful and friendly recipe assistant. \"\n",
    "        \"Summarize the clinical guidelines provided in the context and then tried to answer the user query. \"\n",
    "        \"If the query or guideline provided is not related to depression, please say 'I am not sure about that'. Don't make up things. \"\n",
    "        \n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    ### System Prompt\n",
    "    {system_prompt}\n",
    "\n",
    "    ### User Query\n",
    "    {query}\n",
    "    ### Original Query Results\n",
    "    {json.dumps(original_query_results, indent=2)}\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, new_result in enumerate(new_queries_results):\n",
    "        if new_result[0]:\n",
    "            prompt += f\"\"\"\n",
    "            ### Rewritten Query {i+1}\n",
    "            {new_queries[i]}\n",
    "            ### Results\n",
    "            {json.dumps(new_result, indent=2)}\n",
    "            \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def rewrite_query(query):\n",
    "    system_prompt = (\n",
    "        \"\"\"extract info from the user query to answer the following question.\n",
    "\n",
    "            question:\n",
    "\n",
    "            - Is the patient currently in the acute or maintenance phase of depression treatment, and what symptoms are present?\n",
    "\n",
    "            - Has the patient received pharmacotherapy, psychotherapy, or a combination of both?\n",
    "\n",
    "            - What specific antidepressant medications have been administered so far?\n",
    "\n",
    "            - Is the patient experiencing any side effects or adverse reactions to the current medication?\n",
    "\n",
    "            - Has the patient's condition improved, remained the same, or worsened under the current treatment plan?\n",
    "\n",
    "            make the keyword in your answer bold font,Don't return anything else: Answer each question in a new line, and if the question is not applicable, write \"none\" in that line.\n",
    "            \"\"\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        ### System Prompt\n",
    "        {system_prompt}\n",
    "        ### User Query\n",
    "        {query}\n",
    "        \"\"\"\n",
    "    response = call_llm(prompt)\n",
    "    # clean the response\n",
    "    response = response.split(\"\\n\")\n",
    "    new_queries = [line.strip() for line in response if line.strip()]\n",
    "    # print(\"this is the re-written query\")\n",
    "    # print(response)\n",
    "    \n",
    "    return new_queries\n",
    "\n",
    "def call_llm(prompt):\n",
    "\n",
    "    response = llm_client.chat.completions.create(\n",
    "      model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", #don't change the model!\n",
    "      messages=[\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt\n",
    "          }\n",
    "      ],\n",
    "      max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0795373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- We're using the MedEmbed-large-v0.1 model for embeddings.---------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loaded_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, query \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(queries):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     response = \u001b[43mdepression_assistant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mdepression_assistant\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--------- We\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre using the MedEmbed-large-v0.1 model for embeddings.---------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# original_query_results = search(embedder, query, vector_store, k=4, min_similarity=0.3)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m original_query_results = faiss_search(embedder, query, vector_store, \u001b[43mloaded_index\u001b[49m, k=\u001b[32m4\u001b[39m, min_similarity=\u001b[32m0.3\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m new_queries = rewrite_query(query)\n",
      "\u001b[31mNameError\u001b[39m: name 'loaded_index' is not defined"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(queries):\n",
    "    response = depression_assistant(query)\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answers[i]}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\"*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ef438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
