{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c317040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the following command in terminal to login\n",
    "# huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b836fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file\n",
    "with open(\"../data/raw/queries.txt\", \"r\") as file:\n",
    "    queries = file.readlines()\n",
    "\n",
    "with open(\"../data/raw/answers.txt\", \"r\") as file:\n",
    "    answers = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dce16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f74d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedder = SentenceTransformer(\"abhinand/MedEmbed-large-v0.1\")\n",
    "\n",
    "# similarities = embedder.similarity(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b15293c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/guideline_db_with_img.json\") as f:\n",
    "    db = json.load(f)\n",
    "    \n",
    "with open('../data//processed/Exp2_MedEmb_with_img_table.emb', mode='rb') as f: #replace with your file\n",
    "    vector_store = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vector_store = (\n",
    "#     list()\n",
    "# )\n",
    "\n",
    "# # Step 1 - build vector store\n",
    "# for chunk in db:\n",
    "#     text = chunk[\"text\"]\n",
    "#     embedding = embedder.encode(text)\n",
    "#     vector_store.append({\"text\": text, \"embedding\": embedding, \"metadata\": chunk[\"metadata\"]})\n",
    "\n",
    "# with open('../data/processed/Exp2_NeuML_with_img_table.emb', 'wb') as f:\n",
    "#     pickle.dump(vector_store, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e576fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import difflib\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from together import Together\n",
    "llm_client = Together(api_key='4f6e44b7689d6592b2b5b57ad3940ac9f488d14c22802e8bcdf641b06e98cbbe')\n",
    "#4f6e44b7689d6592b2b5b57ad3940ac9f488d14c22802e8bcdf641b06e98cbbe\n",
    "\n",
    "with open(\"../data/processed/guideline_db.json\") as f:\n",
    "    db = json.load(f)\n",
    "    \n",
    "with open('../data/processed/Exp2_MedEmb.emb', mode='rb') as f: #replace with your file\n",
    "  vector_store = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "def depression_assistant(query):\n",
    "    embedder = SentenceTransformer('abhinand/MedEmbed-large-v0.1')\n",
    "    print(\"--------- We're using the MedEmbed-large-v0.1 model for embeddings.---------\")\n",
    "    \n",
    "    original_query_results = search(embedder, query, vector_store, k=4, min_similarity=0.3)\n",
    "    print(f\"Original query: {query}\")\n",
    "    \n",
    "    new_queries = rewrite_query(query)\n",
    "    new_queries_results = []\n",
    "    \n",
    "    for new_query in new_queries:\n",
    "        if new_query.lower().endswith(\"none**.\") or new_query.lower().endswith(\"none**\"):\n",
    "            print(f\"------- :Rewritten query: {new_query}\")\n",
    "            print(\"------- :No relevant information found in the query, skipping search.\")\n",
    "            new_queries_results.append([None])\n",
    "            continue\n",
    "        print(f\"------- :Rewritten query: {new_query}\")\n",
    "        results = search(embedder, new_query, vector_store, k=4, min_similarity=0.3)\n",
    "        print(f\"------- :Results number: {len(results)}\")\n",
    "        # print(f\"------- :Results: {results}\")\n",
    "        print()\n",
    "        new_queries_results.append(results)\n",
    "        \n",
    "    prompt = construct_prompt(query, original_query_results, new_queries, new_queries_results)\n",
    "    response = call_llm(prompt)\n",
    "    return response\n",
    "\n",
    "def search(embedder, query, vector_store, k, min_similarity):\n",
    "    query_embedding = embedder.encode(query.lower())\n",
    "\n",
    "    similarities = []\n",
    "    results = []\n",
    "    \n",
    "    referenced_tables = list()\n",
    "    # calculate cosine similarity between each text and the query\n",
    "    for i, chunk in enumerate(vector_store):\n",
    "        similarity = cosine_similarity([query_embedding], [chunk[\"embedding\"]])\n",
    "        if similarity[0][0] >= min_similarity:\n",
    "            similarities.append((i, similarity[0][0]))\n",
    "\n",
    "    # sort the similarities based on similarity and select the top k\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i, similarity in similarities[:k]:\n",
    "            results.append({'text':db[i]['text'], 'section': db[i]['metadata']['section'], 'type': db[i]['metadata'].get('referee_id', 'paragraph')})\n",
    "            try:\n",
    "                for table in db[i][\"metadata\"][\"referenced_tables\"]:\n",
    "                    # check if the table is already in the set\n",
    "                    table = table.lower().replace(\" \", \"_\").replace(\".\", \"_\")\n",
    "                    referenced_tables.append(table)\n",
    "            except KeyError:\n",
    "                # if there is no referenced tables, Means this is a table, skip\n",
    "                pass\n",
    "            \n",
    "    referenced_tables = set(referenced_tables)  # remove duplicates\n",
    "    print(referenced_tables)\n",
    "    \n",
    "    \n",
    "    for chunk in results:\n",
    "        #if table is already in the results, skip\n",
    "        try:\n",
    "            if chunk[\"type\"] in referenced_tables:\n",
    "                referenced_tables.remove(chunk[\"type\"])\n",
    "                print(f\"Removed table: {chunk[\"type\"]}\")\n",
    "                print(referenced_tables)\n",
    "        except KeyError:\n",
    "            # if there is no referee_id, skip\n",
    "            pass\n",
    "        \n",
    "\n",
    "    for chunk in db:\n",
    "        try:\n",
    "            if chunk[\"metadata\"][\"referee_id\"] in referenced_tables:\n",
    "                results.append({'text': chunk['text'],'section': chunk['metadata']['section'], 'type': chunk['metadata']['referee_id']})\n",
    "                print(f\"Added table: {chunk['metadata']['referee_id']}\")\n",
    "        except KeyError:\n",
    "            # if there is no referee_id, skip\n",
    "            pass\n",
    "    \n",
    "    if not results or not results[0]:\n",
    "        return [\"No matching documents!\"]\n",
    "    return results\n",
    "\n",
    "\n",
    "def construct_prompt(query, original_query_results, new_queries, new_queries_results):\n",
    "    system_prompt = (\n",
    "        \"Your name is Depression Assistant, a helpful and friendly recipe assistant. \"\n",
    "        \"Summarize the clinical guidelines provided in the context and then tried to answer the user query. \"\n",
    "        \"If the query or guideline provided is not related to depression, please say 'I am not sure about that'. Don't make up things. \"\n",
    "        \n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    ### System Prompt\n",
    "    {system_prompt}\n",
    "\n",
    "    ### User Query\n",
    "    {query}\n",
    "    ### Original Query Results\n",
    "    {json.dumps(original_query_results, indent=2)}\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, new_result in enumerate(new_queries_results):\n",
    "        if new_result[0]:\n",
    "            prompt += f\"\"\"\n",
    "            ### Rewritten Query {i+1}\n",
    "            {new_queries[i]}\n",
    "            ### Results\n",
    "            {json.dumps(new_result, indent=2)}\n",
    "            \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def rewrite_query(query):\n",
    "    system_prompt = (\n",
    "        \"\"\"extract info from the user query to answer the following question.\n",
    "\n",
    "            question:\n",
    "\n",
    "            - Is the patient currently in the acute or maintenance phase of depression treatment, and what symptoms are present?\n",
    "\n",
    "            - Has the patient received pharmacotherapy, psychotherapy, or a combination of both?\n",
    "\n",
    "            - What specific antidepressant medications have been administered so far?\n",
    "\n",
    "            - Is the patient experiencing any side effects or adverse reactions to the current medication?\n",
    "\n",
    "            - Has the patient's condition improved, remained the same, or worsened under the current treatment plan?\n",
    "\n",
    "            make the keyword in your answer bold font,Don't return anything else: Answer each question in a new line, and if the question is not applicable, write \"none\" in that line.\n",
    "            \"\"\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        ### System Prompt\n",
    "        {system_prompt}\n",
    "        ### User Query\n",
    "        {query}\n",
    "        \"\"\"\n",
    "    response = call_llm(prompt)\n",
    "    # clean the response\n",
    "    response = response.split(\"\\n\")\n",
    "    new_queries = [line.strip() for line in response if line.strip()]\n",
    "    # print(\"this is the re-written query\")\n",
    "    # print(response)\n",
    "    \n",
    "    return new_queries\n",
    "\n",
    "def call_llm(prompt):\n",
    "\n",
    "    response = llm_client.chat.completions.create(\n",
    "      model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", #don't change the model!\n",
    "      messages=[\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt\n",
    "          }\n",
    "      ],\n",
    "      max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function to run the depression assistant\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Welcome to the Depression Assistant!\")\n",
    "    print(\"This assistant will help you find relevant information from the clinical guidelines.\")\n",
    "    print(\"You can enter your query and the assistant will try to answer it based on the clinical guidelines.\")\n",
    "    print(\"If you want to exit, just type 'exit' or 'quit'.\")\n",
    "    #run the depression assistant until the user decides to stop\n",
    "    query = input(\"Please enter your query: \")\n",
    "    if not query:\n",
    "        print(\"No query provided. If you want to exit, type 'exit'.\")\n",
    "    while query.lower() not in ['exit']:\n",
    "        #if the query is not empty, run the depression assistant\n",
    "        if query.strip():\n",
    "            response = depression_assistant(query)\n",
    "            #while we're still processing the response, tell the user we're working on it\n",
    "            print(\"Processing your query, please wait...\")\n",
    "            print(f\"------------------This is the response from the Depression Assistant: {response}-------------------\")\n",
    "        else:\n",
    "            print(\"No query provided. If you want to exit, type 'exit'.\")\n",
    "        query = input(\"Please enter your query: \")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0795373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- We're using the MedEmbed-large-v0.1 model for embeddings.---------\n",
      "{'table_2_4', 'table_3_7', 'table_a'}\n",
      "Original query: My patient is interested in lifestyle interventions for a major depressive episode of mild severity that does not have a seasonal pattern. What is the first line recommendation?\n",
      "\n",
      "------- :Rewritten query: - The patient is currently in the **acute** phase of depression treatment, and symptoms of a major depressive episode of **mild** severity are present.\n",
      "{'table_a'}\n",
      "------- :Results number: 4\n",
      "\n",
      "------- :Rewritten query: - The patient has not received **pharmacotherapy** or **psychotherapy** yet, as they are interested in **lifestyle** interventions.\n",
      "{'table_a'}\n",
      "------- :Results number: 4\n",
      "\n",
      "------- :Rewritten query: - **None**\n",
      "------- :No relevant information found in the query, skipping search.\n",
      "------- :Rewritten query: - **None**\n",
      "------- :No relevant information found in the query, skipping search.\n",
      "------- :Rewritten query: - **None**\n",
      "------- :No relevant information found in the query, skipping search.\n",
      "--------------------------------------------------\n",
      "Query: My patient is interested in lifestyle interventions for a major depressive episode of mild severity that does not have a seasonal pattern. What is the first line recommendation?\n",
      "\n",
      "Answer: Supervised exercise (low to moderate intensity, 30-40 mins at a time, 3-4 weeks, minimum of 9 weeks)\n",
      "\n",
      "Response: The clinical guidelines provided suggest that for a major depressive episode of mild severity without a seasonal pattern, lifestyle interventions can be considered as a first-line treatment. \n",
      "\n",
      "According to the guidelines, exercise is recommended as a first-line monotherapy for mild depression. Specifically, supervised exercise of low to moderate intensity, for 30 to 40 minutes at a time, 3 to 4 times a week, for a minimum of 9 weeks, is supported by evidence as an effective treatment for mild depression.\n",
      "\n",
      "Additionally, other lifestyle modifications such as a healthier diet, smoking cessation, and sleep hygiene are also beneficial in managing depressive episodes.\n",
      "\n",
      "Therefore, for a patient interested in lifestyle interventions for a major depressive episode of mild severity without a seasonal pattern, exercise can be considered as a first-line recommendation, along with other lifestyle modifications.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(queries):\n",
    "    response = depression_assistant(query)\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answers[i]}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\"*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ef438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
